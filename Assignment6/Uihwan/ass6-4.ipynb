{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI1RiMnkloZ8UpXIZeAJ0C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skdmlnatas/business-data/blob/main/Assignment6/Uihwan/ass6-4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick Question. What is Instance segmentation, and how it is different from Semantic Segmentation?"
      ],
      "metadata": {
        "id": "JM1fLhErKplx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지에서 객체의 경계를 예측하는 것.</br> 각 인스턴스끼리 구별하는지가 다름."
      ],
      "metadata": {
        "id": "S950hLuCK4wY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sF3X141EKoiy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q segmentation-models-pytorch ## installing a special library for segmentation"
      ],
      "metadata": {
        "id": "ivW_hAa1LVHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# 런타임 - 런타임 유형 변경 - T4 GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "TOT4wvztLWu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = 'ENTER YOUR DIRECTORY'\n",
        "IMAGE_PATH = os.path.join(ROOT, 'images')\n",
        "MASK_PATH = os.path.join(ROOT, 'masks')\n",
        ""
      ],
      "metadata": {
        "id": "jZEBKEITLY01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir(IMAGE_PATH))) ## # of images\n",
        "assert len(os.listdir(IMAGE_PATH)) == len(os.listdir(MASK_PATH)) # check of the # of images and # of masks are the same\n",
        "# If not, assertion error comes out, and remaining shells & commands will not be executed"
      ],
      "metadata": {
        "id": "eirrpH9PLaUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 5 ## there are 5 classes - check the Kaggle website (background, car, wheel, light, and windows)\n",
        "\n",
        "def create_df():\n",
        "    name = []\n",
        "    for dirname, _, filenames in os.walk(IMAGE_PATH):\n",
        "        for filename in filenames:\n",
        "            name.append(filename.split('.')[0])\n",
        "\n",
        "    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n",
        "\n",
        "df = create_df()\n",
        "print('Total Images: ', len(df))"
      ],
      "metadata": {
        "id": "mKLOQ3GALb2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting data\n",
        "X_train, X_val = train_test_split(df['id'][:100].values, train_size=0.8, random_state=19) # For now, let's just use 100 images\n",
        "\n",
        "print('Train Size   : ', len(X_train))\n",
        "print('Val Size     : ', len(X_val))"
      ],
      "metadata": {
        "id": "ZmbyZ9nsLdfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(IMAGE_PATH + df['id'][50] + '.png')\n",
        "mask = Image.open(MASK_PATH + df['id'][50] + '.png')\n",
        "print('Image Size', np.asarray(img).shape)\n",
        "print('Mask Size', np.asarray(mask).shape)\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.imshow(mask, alpha=0.6)\n",
        "plt.title('Picture with Mask Appplied') ## Randomly choose one sample\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kHyhKzdrLesh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.X = X\n",
        "        self.transform = transform\n",
        "        self.patches = patch\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.img_path + self.X[idx] + '.png')\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            aug = self.transform(image=img, mask=mask)\n",
        "            img = Image.fromarray(aug['image'])\n",
        "            mask = aug['mask']\n",
        "\n",
        "        if self.transform is None:\n",
        "            img = Image.fromarray(img)\n",
        "\n",
        "        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n",
        "        img = t(img)\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "\n",
        "        if self.patches:\n",
        "            img, mask = self.tiles(img, mask)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "    def tiles(self, img, mask):\n",
        "\n",
        "        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768)\n",
        "        img_patches  = img_patches.contiguous().view(3,-1, 512, 768)\n",
        "        img_patches = img_patches.permute(1,0,2,3)\n",
        "\n",
        "        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n",
        "        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n",
        "\n",
        "        return img_patches, mask_patches"
      ],
      "metadata": {
        "id": "fCpZo09dLgc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "t_train = A.Compose([A.Resize(256, 256, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(),\n",
        "                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n",
        "                     A.GaussNoise()])\n",
        "\n",
        "t_val = A.Compose([A.Resize(256, 256, interpolation=cv2.INTER_NEAREST)])\n",
        "\n",
        "#datasets\n",
        "train_set = CarDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)\n",
        "val_set = CarDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n",
        "\n",
        "#dataloader\n",
        "batch_size= 3\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
        ""
      ],
      "metadata": {
        "id": "D0zrKsPgLiFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.Unet('efficientnet-b0', encoder_weights='imagenet', classes=5, activation=None, encoder_depth=5)\n",
        ""
      ],
      "metadata": {
        "id": "tCrVYlK_Ljnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "t50Kxn3NLkyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_accuracy(output, mask):\n",
        "    with torch.no_grad():\n",
        "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        correct = torch.eq(output, mask).int()\n",
        "        accuracy = float(correct.sum()) / float(correct.numel())\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "6-JJYZe9LmLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=5):\n",
        "    with torch.no_grad():\n",
        "        pred_mask = F.softmax(pred_mask, dim=1)\n",
        "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
        "        pred_mask = pred_mask.contiguous().view(-1)\n",
        "        mask = mask.contiguous().view(-1)\n",
        "\n",
        "        iou_per_class = []\n",
        "        for clas in range(0, n_classes): #loop per pixel class\n",
        "            true_class = pred_mask == clas\n",
        "            true_label = mask == clas\n",
        "\n",
        "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
        "                iou_per_class.append(np.nan)\n",
        "            else:\n",
        "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
        "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
        "\n",
        "                iou = (intersect + smooth) / (union +smooth)\n",
        "                iou_per_class.append(iou)\n",
        "        return np.nanmean(iou_per_class)"
      ],
      "metadata": {
        "id": "DoFtH0JULnrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def dice(pred_mask, mask, smooth=1e-10, n_classes=5):\n",
        "    with torch.no_grad():\n",
        "        pred_mask_softmax = F.softmax(pred_mask, dim=1)\n",
        "        pred_mask_argmax = torch.argmax(pred_mask_softmax, dim=1)\n",
        "        pred_mask_flatten = pred_mask_argmax.contiguous().view(-1)\n",
        "        mask_flatten = mask.contiguous().view(-1)\n",
        "\n",
        "        dice_per_class = []\n",
        "\n",
        "        for clas in range(0, n_classes):  # loop per pixel class\n",
        "            true_class = pred_mask_flatten == clas\n",
        "            true_label = mask_flatten == clas\n",
        "\n",
        "            if true_label.long().sum().item() == 0:  # no exist label in this loop\n",
        "                dice_per_class.append(np.nan)\n",
        "            else:\n",
        "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
        "                dice = (2 * intersect + smooth) / (true_class.sum().float() + true_label.sum().float() + smooth)\n",
        "                dice_per_class.append(dice)\n",
        "\n",
        "        return np.nanmean(dice_per_class)"
      ],
      "metadata": {
        "id": "vadLRikeLpif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick Question. What's (1) pixel accuracy, (2) mIOU, and (3) Dice score? Google it and write your own answer."
      ],
      "metadata": {
        "id": "JNrzNob8LrIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 각 픽셀을 얼마나 정확히 분류했냐</br>\n",
        "2. 예측 분할과 실제 분할의 교집합과 합집합의 비율<br/>\n",
        "3. 크기+크기 분에 교집합 두배"
      ],
      "metadata": {
        "id": "nPIYfoWaMC_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n",
        "    torch.cuda.empty_cache()\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    val_iou = []; val_dice = []; val_acc = []\n",
        "    train_iou = []; train_dice = []; train_acc = []\n",
        "    lrs = []\n",
        "    min_loss = np.inf\n",
        "    decrease = 1 ; not_improve=0\n",
        "\n",
        "    model.to(device)\n",
        "    fit_time = time.time()\n",
        "    for e in range(epochs):\n",
        "        since = time.time()\n",
        "        running_loss = 0\n",
        "        iou_score = 0\n",
        "        dice_score = 0\n",
        "        accuracy = 0\n",
        "        #training loop\n",
        "        model.train()\n",
        "        for i, data in enumerate(tqdm(train_loader)):\n",
        "            #training phase\n",
        "            image_tiles, mask_tiles = data\n",
        "            if patch:\n",
        "                bs, n_tiles, c, h, w = image_tiles.size()\n",
        "\n",
        "                image_tiles = image_tiles.view(-1,c, h, w)\n",
        "                mask_tiles = mask_tiles.view(-1, h, w)\n",
        "\n",
        "            image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
        "            #forward\n",
        "            output = model(image)\n",
        "            loss = criterion(output, mask)\n",
        "            #evaluation metrics\n",
        "            iou_score += mIoU(output, mask)\n",
        "            dice_score += dice(output, mask)\n",
        "            accuracy += pixel_accuracy(output, mask)\n",
        "            #backward\n",
        "            loss.backward()\n",
        "            optimizer.step() #update weight\n",
        "            optimizer.zero_grad() #reset gradient\n",
        "\n",
        "            #step the learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        else:\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            test_accuracy = 0\n",
        "            val_iou_score = 0\n",
        "            val_dice_score = 0\n",
        "            #validation loop\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(tqdm(val_loader)):\n",
        "                    #reshape to 9 patches from single image, delete batch size\n",
        "                    image_tiles, mask_tiles = data\n",
        "\n",
        "                    if patch:\n",
        "                        bs, n_tiles, c, h, w = image_tiles.size()\n",
        "\n",
        "                        image_tiles = image_tiles.view(-1,c, h, w)\n",
        "                        mask_tiles = mask_tiles.view(-1, h, w)\n",
        "\n",
        "                    image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
        "                    output = model(image)\n",
        "                    #evaluation metrics\n",
        "                    val_iou_score +=  mIoU(output, mask)\n",
        "                    val_dice_score += dice(output, mask)\n",
        "                    test_accuracy += pixel_accuracy(output, mask)\n",
        "                    #loss\n",
        "                    loss = criterion(output, mask)\n",
        "                    test_loss += loss.item()\n",
        "\n",
        "            #calculatio mean for each batch\n",
        "            train_losses.append(running_loss/len(train_loader))\n",
        "            test_losses.append(test_loss/len(val_loader))\n",
        "\n",
        "\n",
        "            if min_loss > (test_loss/len(val_loader)):\n",
        "                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n",
        "                min_loss = (test_loss/len(val_loader))\n",
        "                decrease += 1\n",
        "                if decrease % 5 == 0:\n",
        "                    print('saving model...')\n",
        "#                     torch.save(model, 'Unet-Efficient_IoU-{:.3f}-femur1.pt'.format(val_iou_score/len(val_loader)))\n",
        "\n",
        "            if (test_loss/len(val_loader)) > min_loss:\n",
        "                not_improve += 1\n",
        "                min_loss = (test_loss/len(val_loader))\n",
        "                print(f'Loss Not Decrease for {not_improve} time')\n",
        "                if not_improve == 7:\n",
        "                    print('Loss not decrease for 7 times, Stop Training')\n",
        "                    break\n",
        "\n",
        "            #iou\n",
        "            val_iou.append(val_iou_score/len(val_loader))\n",
        "            train_iou.append(iou_score/len(train_loader))\n",
        "            val_dice.append(val_dice_score/len(val_loader))\n",
        "            train_dice.append(dice_score/len(train_loader))\n",
        "            train_acc.append(accuracy/len(train_loader))\n",
        "            val_acc.append(test_accuracy/ len(val_loader))\n",
        "            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
        "                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
        "                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n",
        "                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
        "                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
        "                  \"Train dice:{:.3f}..\".format(dice_score/len(train_loader)),\n",
        "                  \"Val dice:{:.3f}..\".format(val_dice_score/len(val_loader)),\n",
        "                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n",
        "                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n",
        "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
        "\n",
        "    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n",
        "               'train_miou' :train_iou, 'val_miou':val_iou,\n",
        "               'train_dice' :train_dice, 'val_dice':val_dice,\n",
        "               'train_acc' :train_acc, 'val_acc':val_acc,\n",
        "               'lrs': lrs}\n",
        "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
        "    return history"
      ],
      "metadata": {
        "id": "1nKIsXgcLuKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_lr = 1e-3\n",
        "epoch = 30\n",
        "weight_decay = 1e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
        "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
        "                                            steps_per_epoch=len(train_loader))\n",
        "\n",
        "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)"
      ],
      "metadata": {
        "id": "cneI-PUqLw9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'car-segmentation-unet-1.pt')"
      ],
      "metadata": {
        "id": "oZpl3YnxLyJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history):\n",
        "    plt.plot(history['val_loss'], label='val', marker='o')\n",
        "    plt.plot( history['train_loss'], label='train', marker='o')\n",
        "    plt.title('Loss per epoch'); plt.ylabel('loss');\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_score(history):\n",
        "    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n",
        "    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n",
        "    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_acc(history):\n",
        "    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n",
        "    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n",
        "    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_dice(history):\n",
        "    plt.plot(history['train_dice'], label='train_dice', marker='*')\n",
        "    plt.plot(history['val_dice'], label='val_dice',  marker='*')\n",
        "    plt.title('dice per epoch'); plt.ylabel('dice')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "6PWvBrPzL0He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)\n",
        "plot_score(history)\n",
        "plot_acc(history)\n",
        "plot_dice(history)\n",
        ""
      ],
      "metadata": {
        "id": "sVQc4SaWL1ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_path, mask_path, X, transform=None):\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.X = X\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.img_path + self.X[idx] + '.png')\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            aug = self.transform(image=img, mask=mask)\n",
        "            img = Image.fromarray(aug['image'])\n",
        "            mask = aug['mask']\n",
        "\n",
        "        if self.transform is None:\n",
        "            img = Image.fromarray(img)\n",
        "\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "\n",
        "t_test = A.Resize(256, 256, interpolation=cv2.INTER_NEAREST)\n",
        "test_set = CarDataset(IMAGE_PATH, MASK_PATH, X_val, transform=t_test)"
      ],
      "metadata": {
        "id": "qoP0pMj1L3Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    model.eval()\n",
        "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
        "    image = t(image)\n",
        "    model.to(device); image=image.to(device)\n",
        "    mask = mask.to(device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        image = image.unsqueeze(0)\n",
        "        mask = mask.unsqueeze(0)\n",
        "        mask2 = mask.cpu()\n",
        "\n",
        "        output = model(image)\n",
        "        score = mIoU(output, mask)\n",
        "        masked = torch.argmax(output, dim=1)\n",
        "        masked = masked.cpu().squeeze(0)\n",
        "\n",
        "\n",
        "    return masked, score"
      ],
      "metadata": {
        "id": "ecWRbJ-uL4pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_mask_pixel(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    model.eval()\n",
        "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
        "    image = t(image)\n",
        "    model.to(device); image=image.to(device)\n",
        "    mask = mask.to(device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        image = image.unsqueeze(0)\n",
        "        mask = mask.unsqueeze(0)\n",
        "\n",
        "        output = model(image)\n",
        "        acc = pixel_accuracy(output, mask)\n",
        "        masked = torch.argmax(output, dim=1)\n",
        "        masked = masked.cpu().squeeze(0)\n",
        "    return masked, acc"
      ],
      "metadata": {
        "id": "UR35jOAaL6Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, mask = test_set[3]\n",
        "pred_mask, score = predict_image_mask_miou(model, image, mask)"
      ],
      "metadata": {
        "id": "JQvJoT80L8BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def miou_score(model, test_set):\n",
        "    score_iou = []\n",
        "    for i in tqdm(range(len(test_set))):\n",
        "        img, mask = test_set[i]\n",
        "        pred_mask, score = predict_image_mask_miou(model, img, mask)\n",
        "        score_iou.append(score)\n",
        "    return score_iou\n",
        "\n",
        "mob_miou = miou_score(model, test_set)\n",
        ""
      ],
      "metadata": {
        "id": "xfpszdulL9S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_acc(model, test_set):\n",
        "    accuracy = []\n",
        "    for i in tqdm(range(len(test_set))):\n",
        "        img, mask = test_set[i]\n",
        "        pred_mask, acc = predict_image_mask_pixel(model, img, mask)\n",
        "        accuracy.append(acc)\n",
        "    return accuracy\n",
        "\n",
        "mob_acc = pixel_acc(model, test_set)"
      ],
      "metadata": {
        "id": "787IljLmL-c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n",
        "ax1.imshow(image)\n",
        "ax1.set_title('Input');\n",
        "ax1.set_axis_off()\n",
        "\n",
        "\n",
        "ax2.imshow(mask)\n",
        "ax2.set_title('Ground truth')\n",
        "ax2.set_axis_off()\n",
        "\n",
        "ax3.imshow(pred_mask)\n",
        "ax3.set_title('UNet-EfficientNet-b0 | IoU {:.3f}'.format(score))\n",
        "ax3.set_axis_off()"
      ],
      "metadata": {
        "id": "qWjjskh7L_yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1. Write a brief explanation of the entire code. Just try to get the feel for this file. ChatGPT allowed!\n"
      ],
      "metadata": {
        "id": "7UFZXV-LMBJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "segmentation 기법들에 대한 코드"
      ],
      "metadata": {
        "id": "9VCMSxK2NARI"
      }
    }
  ]
}